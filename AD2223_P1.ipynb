{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ADlu8E-uPSm"
      },
      "outputs": [],
      "source": [
        "# Setup, Version check and Common imports\n",
        "\n",
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os \n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST dataset from keras datasets: https://keras.io/api/datasets/mnist/\n",
        "# The load_data() method creates train and test sets\n",
        "\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "id": "GQHG3Py_8ASq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm the shape of the training sets\n",
        "\n",
        "print(train_images.shape)\n",
        "\n",
        "print(train_labels.shape)"
      ],
      "metadata": {
        "id": "z2f0GaOb8NzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize one instance\n",
        "\n",
        "print(train_labels[0])\n",
        "\n",
        "print(train_images[0])\n"
      ],
      "metadata": {
        "id": "FijMkVAp8gPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced visualization of one example. \n",
        "# Modify the value of index to visualize other examples from the training set\n",
        "\n",
        "index = 0\n",
        "\n",
        "plt.title(train_labels[index], fontsize=16)\n",
        "plt.imshow(train_images[index])"
      ],
      "metadata": {
        "id": "GzvzTGnP84i3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a simple feed-forward NN with name my_first_model\n",
        "# It relies on the Keras Sequential API: https://keras.io/api/models/\n",
        "# When creating a NN, it adds layeys one by one, using the layer class: https://keras.io/api/layers/base_layer/\n",
        "\n",
        "my_first_model = keras.Sequential([\n",
        "    layers.Flatten(input_shape=[28,28]),\n",
        "    layers.Dense(512, activation=\"sigmoid\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "KIW-AQfo-MXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quiz**\n",
        "\n",
        "1. How many layers has my_first_model?\n",
        "\n",
        "2. How many parameters has my_first_model?\n",
        "\n",
        "3. Can you justify the need of the Flatten layer?\n",
        "\n",
        "3. Can you justify the selection of the activation functions?\n"
      ],
      "metadata": {
        "id": "dNPeotS9FM4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Present a summary of the network architecture\n",
        "# Confirm if your answers are correct\n",
        "\n",
        "my_first_model.summary()"
      ],
      "metadata": {
        "id": "xYA6XRd7_D7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A NN has to be compiled by calling the compile() method: https://keras.io/api/models/model_training_apis/\n",
        "# Three components have to be defined (recall how backpropagation is appplied during training):\n",
        "# 1. the Optimizer to be used in training\n",
        "# 2. The loss function\n",
        "# 3. The evaluation metric \n",
        "\n",
        "my_first_model.compile(optimizer=\"SGD\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "Mw3QHyCA_18E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training is performed by calling the fit() method: https://keras.io/api/models/model_training_apis/\n",
        "\n",
        "my_first_model.fit(train_images, train_labels, epochs=5, batch_size=128)\n"
      ],
      "metadata": {
        "id": "1QP9qcZyAAuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quiz**\n",
        "\n",
        "1. Explain the parameters specified in the fit() method?\n",
        "\n",
        "2. Can you observe any evidence that training is being successful?\n"
      ],
      "metadata": {
        "id": "SJdhLe3txwwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation the generalization ability of the model\n",
        "# The test set will be used in this step\n",
        "# Classification of a set of examples can be performed using the evaluate() method:  https://keras.io/api/models/model_training_apis/\n",
        "\n",
        "test_loss, test_acc = my_first_model.evaluate(test_images, test_labels)\n",
        "print(f\"test_acc: {test_acc}\")"
      ],
      "metadata": {
        "id": "c6TS3KD3AqfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quiz**\n",
        "\n",
        "1. How do you analyse this result?\n",
        "\n",
        "2. Why is it important to evaluate the model on a test set?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZqaenAjIzgMU"
      }
    }
  ]
}